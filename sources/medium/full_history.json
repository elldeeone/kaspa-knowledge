[
  {
    "title": "In which we are all faceless until we have faces (Part I)*",
    "link": "https://hashdag.medium.com/in-which-we-are-all-faceless-until-we-have-faces-part-i-5f100e0555a4?source=rss-400d0e2aab3b------2",
    "summary": "<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*XQ5qFhp8zBsSlnRbl68xAw.jpeg\" /><figcaption>PROOF OF DWORK</figcaption></figure><h3><strong>Ur of the Chaldees</strong></h3><p>I am the sole culprit behind the recent sagas surrounding “our” X account and the name of Kaspa’s atomic unit. It was my own doing; regrettably, I have no accomplices to share the credit with. I genuinely empathize with fellow Kaspers who felt confused, distressed, or deflated by my actions. Though I cannot offer a sincere apology, I can and should offer more context.</p><p>The reader should be warned in advance that my argument will be constructed rather ouroboros-ly, in a manner which makes it illogical to refute. The more the reader disagrees with it the more they are forced to recognize the validity and relevance of the argument. I learnt this little trick of constructing self-enforcing arguments from one old Chaldean family from the 19th century BC, whose story is not entirely irrelevant to ours.</p><p>Terah was a Mesopotamian idol manufacturer. The <em>Midrash of Genesis</em> (tales by Jewish sages) describes how one morning Terah left his son Abraham to watch the idol shop. Abraham seized the moment and took a stick and smashed all the idols, except the largest one. He then placed the stick in the hand of that remaining idol. When Terah returned and saw the destruction, he demanded, “What happened here?” Abraham replied, “The idols got into a quarrel, and the big one decided to smash the rest.” Terah exclaimed, “Do you think I’m a fool? These idols have no knowledge or power!” And Abraham replied, “Then let your ears hear what your mouth is saying.”</p><p>Some odd 48 hours ago someone left the largest idol alone with access to Kaspa’s official X account. I consulted no one before changing the account from “Kaspa” to “Kaspa (Unofficial)”, nor did I prepare any crisis management plan. Though, perhaps like Terah’s son, I have waited for the right moment for a long time.</p><h3>The Bourne Identity</h3><p>To the extent that this saga turns into an identity crisis for many Kaspa fans, it is a long-overdue one.</p><p>There is a choice to be made: Are we here for the cozy feeling of a cohesive community with a welcoming center of the hub, or are we committed to penetrating the crypto — thence the broader — market with a p2p electronic cash system and a trustworthy store of value?</p><p>In the past 18 months, the marketcap of bitcoin surpassed that of silver, twice. What would it take for us to be able to think of KAS in similar terms?</p><p>The technology of Kaspa is superior to Bitcoin’s many times over, largely due to elite architecture and execution by Crescendo devs. But why is Kaspa Crescendo celebrated? Because it achieves a 6000x improvement over Satoshi’s protocol whilst remaining in the confines of the same trust model — a center-less structure which delegates the control over the network to an anonymous set of miners. A set which, to be explicit, comprises egoistic entities that should never be trusted, and yet whose competing incentives align with that of securing the network.</p><p>There are dozens of crypto projects which offer much richer tech stacks, production live apps, and marketing budgets than kaspa or bitcoin. Kaspa’s value can be unlocked and recognized only only only if Kaspa is-looks-feels-smells culturally open-source, practically center-less, constitutionally principled.</p><p>The existence of an official social account simply fails the gut check.</p><h3>A public mask of the project</h3><p>The main social account, practically an official one, with announcements and press releases, is convenient and facilitative indeed, and could be argued to have been instrumental early on. It is nonetheless a headquarters of the brand, and those who populate the headquarters are inadvertently co-opting the identity of the network. The consolidation of influence becomes inevitable, whether or not the people controlling the socials would consciously choose such an outcome.</p><p>Despite the dogmatic sound of the argument, it is no less a pragmatic one; I became conscious of it through observation more than through first-principles thinking. Specifically, I observed that for a team building a product or layer atop Kaspa, the best approach at community engagement and capture is through the conviction, if not friendship, of the maintainers of the social accounts. Alignment with them is an asset, misalignment — a liability. Needless to spell out the consequences: Even if the main accounts are governed with virtue and kept far from corrupt, a hierarchy forms — one which is easily spotted by newcomers. Visitors and newcomers are the first to recognize the whos and whats of the in-group, and through their experiences I became increasingly aware how our community is increasingly losing its flat hierarchy, its mission, and its chances at fulfilling it.</p><p>To be maximally unambiguous about this — the individuals who maintained so far the socials would never opt to gain power or deliberate influence. When interacting with them, I was inspired by their firm belief and selfless devotion to Kaspa’s mission; they truly love Kaspa, resembling perhaps the love and devotion of the mother-GHOST, from CS Lewis’ The Great Divorce, to the spirit of her son Michael.</p><p>In particular, they have never undermined the authority of Kaspa Core; had they attempted to do so, that would be a breath of fresh air. The issue we are highlighting here, therefore, has to do with representation more than with alignment. Many Kaspa X’ers hold paradigms, mental models, or style that I — and other members of Core — object to. This is perfectly normal and nothing needs to be done about it. We are not, however, seen as represented by any of these accounts. In contrast, with the official X account, the interpretation is different: It is the most followed Kaspa account, it is named plainly “Kaspa”, it offers press releases and formally-styled updates, and it actively nurtures the brand. We, Kaspa members, and especially Kaspa Core, are practically represented by it; it is a forced mask on the face of the project and of Core, and no matter how good the maintainers are at their jobs, it is still a mask.</p><p>I trust the reader to not be confused by my admission that these individuals understand brand-building at a deeply higher level than I do, and that they have been undoubtedly instrumental to the growth of Kaspa community and brand. If someone asked me in the future regarding the expertise of these individuals, I would unquestionably recommend them and vouch for their brand-building-and-nurturing expertise, my lack of experience in marketing being the only reservation to a warm recommendation and a big yes.</p><p>My argument notwithstanding.</p><h3><strong>Second things first</strong></h3><p>Reflecting on the media of exchange of ancient man, and of modern primitive societies, one can argue there exists a reverse correlation between the degree of cohesiveness of a society — which can be achieved at scale only through rigid hierarchies — and the moneyness qualities of its MoE. A strictly hierarchical society, the Andean Inca for instance, was able to thrive with barter and social obligations alone; their hierarchical structure replaced many functionalities that money serves in modern civilization, such as the allocation of resources and the flow of information. More heterogeneous civilizations had to adopt more scalable MoE — cowrie, to name one notable example — with barter frequently still coexisting, as in the city-states of Yoruba. Further along the spectrum (chronology aside), the merchant-oriented Mesopotamian civilizations utilized silver for payment and accounting — a yet more scalable and practical medium of exchange for urban, complex trade.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/410/1*LX88o4dMtpgVLxwvtofjtQ.jpeg\" /><figcaption>By Published by Guillaume Rouille(1518?-1589) — “Promptuarii Iconum Insigniorum “, Public Domain, <a href=\"https://commons.wikimedia.org/w/index.php?curid=8804631\">https://commons.wikimedia.org/w/index.php?curid=8804631</a></figcaption></figure><p>Is it a good thing then to describe Kaspa community as united and conflict-free? This community is one of the friendliest and welcoming communities in crypto. Compared to Bitcoin 2014–5 it is virtually toxic-free. The atmosphere, at least that projected by the brand’s headquarters, is almost too positive and worry-free.¹</p><p>Yet, getting too attached to the friendly vibes, or over-priding ourselves on that, would be “putting second things first”, to borrow CS Lewis’ phrase. We should prioritize debates, rebuts, arguments, disputes, concerns. There are serious challenges ahead of Kaspa — security budget, decentralized governance, monolithic vs modular architecture, HF policies, open-source funding, degen vs elitism, L2 fragmentation — and if we are not fighting over those issues we are probably doing something wrong. Probably, we are delusional about their seriousness, or worse yet delusional about Terah’s ability to solve them all through the genius of his idols.</p><p>First things first, for Kaspa to become a money, a globally trusted asset in the order of today’s trillions of US dollars, the community’s culture must be conducive to becoming the cradle of money. Some degree of tension and contention must linger in the air for the moneyness properties of a society’s collectible to emerge. Our rivals, our competitors and adversaries, must feel comfortable storing their wealth herein. High net worth individuals who distrust this author — hopefully the club has grown larger in the past 48 hours — must feel Kaspa is nonetheless an absolute safe haven for their wealth. It must pass the eye test of institutional investors. Kaspa must Bitcoinize.</p><h3><strong>Ethereum, North Korea, Vitalik</strong></h3><p>Ethereum is the most important crypto platform alongside Bitcoin.² No-one in Ethereum epicenter was seriously considering a rollback after the ByBit hack, the psyops notwithstanding. Ethereum is orders-of-magnitude more mature and distributed than it was in the DAO hack days. Nonetheless, the ByBit hack can be used as a thought experiment to reflect on hierarchies and their implication to moneyness.</p><p>In spring 2016 I was invited by Andrew Miller to Cornell, where he and Elaine and Emin Gun organized an Ethereum bootcamp. Around that time, Emin voiced the DAO vulnerabilities (eg <a href=\"https://x.com/el33th4xor/status/736266834073276416\">https://x.com/el33th4xor/status/736266834073276416</a>), and a few days later the vulnerabilities were exploited by an anonymous “code-is-law” hacker. It so happened that the bootcamp took place during the intervention — technically not a rollback but a manual HF to induce an irregular state transition. The Ethereum squad attended the bootcamp as well, and we all followed closely the community’s anticipation/support/outrage, the Classic split.</p><p>While Ethereum matured since — one year later, Vitalik didn’t initiate a reversal of the Parity hack and the wallet freeze — one can argue that the effects of the DAO intervention are lasting: The primary effect of the intervention was not the violation of code-is-law rather the cementing of Vitalik’s position as the ruling arbiter. The decision not to reverse Parity was still perceived as Vitalik’s call rather than an inevitable consequence.</p><p>Whether a code-is-law view should be adopted should be a discussion for another day. Suffice it to say that a puritan stance lacks completeness in that it does not address systemic collapses — a breaking of the hash function, to provide an extreme example — or a huge 51% attack — where the social consensus will anyways violate the code’s dictation this way or another (I will post later a seemingly conflicting post regarding a WWIII-resilient finality adjustment protocol).</p><p>Code-is-law being less relevant, the discussion or rather reflection should evolve around the structure of the social-political-economic graph which shapes the social consensus, at least post catastrophic failures. And in the case of Ethereum, the network exhibits a supernode, a brilliant, reasonable, and responsible one, a single point of pressure nonetheless.</p><p>This is not to insinuate Vitalik has omnipotent power in the community; this is far from the reality of the community. Vitalik cannot pull off arbitrary code-change or impose protocol modification at his whim, he cannot act capriciously, his decisions face scrutiny, similarly to other leaders in structured organizations which are more often than not constrained by protocols and customary processes. It is not even to claim Ethereum is centralized — -this tired label is by now emptied from any tangible meaning by narrative grunts, and should be discarded. This is merely to say Ethereum is as robust as Vitalik is. It is far from being antifragile.</p><p>(Antifragility is a very useful adjective, coined by Taleb, and [GPT:] refers to a system or entity that not only withstands stress and shocks but actually benefits and grows stronger from them. Unlike robustness, which resists damage but does not improve, antifragile systems thrive in uncertainty and volatility.)</p><p>Again, this argument does not undermine Ethereum’s supremacy nor Vitalik’s leadership; the reader can acknowledge those and still comfortably remain an eth maxi. This is merely to point to the centrality of Ethereum’s social graph, to its single point of pressure, which is admittedly risky only in black swan events, but crypto is quite a hotbed for black swans:</p><p>Consider for instance a scenario where OFAC used the DAO precedent to force the hands of Vitalik and the EF to rollback the ByBit hack, lest they be deemed liable for being complicit in violating US sanctions. It is difficult to predict how would Vitalik and EF react in such a turn of events, and what would the community’s expectation and social consensus be in this scenario.</p><h3>Conquest’s second law</h3><p>Can Ethereum rearrange its social graph? I recollect Conquest’s second law of politics which states that an organization not constitutionally right-wing (or freedom maxi) will inevitably become left-wing (admin/intervention maxi), which should translate in crypto terms to: A project not constitutionally decentralized will inevitably centralize and ossify. In my head, I call this the reverse second law of cryptodynamics. (<a href=\"https://x.com/hashdag/status/1683507762204909568\">https://x.com/hashdag/status/1683507762204909568</a>).</p><p>Vitalik has historically evaded the question of Ethereum’s “moneyness”. In discussions I had with him in the past he rather dismissed this value proposition, and his public stance too was and still is non-committal. To me, this vague stance suggested not a lack of rigor but a recognition of the elusiveness of money — one can argue money is more of an emergent property of a commodity or asset rather than a defined checklist that an asset must satisfy in order to deserve the money title. Ethereum’s mindset is by and large consistent with &lt;Ethereum is tech; money is a rhetorical device; by adoption of the tech we achieve de facto a behaviour that is indistinguishable from money&gt;:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/979/1*JioJMKGxkQi6QdcDRWYZxA.png\" /></figure><p>This tech-oriented stance is quite reasonable and pragmatic, albeit shortsighted. Historically, widespread adoption has indeed upgraded many commodities into moneys, irrespective of their soundness traits (whatever exact criteria this entails). In the long term, however, these moneys were replaced by collectibles which were optimized for moneyness properties to begin with. Cf. <a href=\"https://unenumerated.blogspot.com/2016/07/artifacts-of-wealth-patterns-in_15.html\">Nick Szabo’s essay</a> on the origin of money (not coincidentally, Nick was one of the biggest supporters of the code-is-law stance towards the DAO hack.)</p><p>To complete the context, the current argument in Bitcoin circles regarding an OP_CAT plugin pertains, on a deeper level, to the question whether Bitcoin’s path from collectible to money is secured by the mere demand for it as store of value/e-gold; or rather an additional demand as a utility, e.g. a defi rails, is needed to support its moneyness, and without such demand it will remain “a Rolex”.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/624/1*sKfeVdfyhFTV13-wBwXrcA.png\" /></figure><h3><strong>Crescendo mainnet launch</strong></h3><p>Kaspa humbly suggests that a defi rails should satisfy the property of intra-round (simply: real-time) censorship resistant sequencing with subsecond confirmation (/inclusion) times, rather than inclusion times in the order of 10 minutes and censorship-resistance latency in the order of 1 hour.</p><p>There is a sense, therefore, that Crescendo feels like a second mainnet launch of Kaspa. For the reasons mentioned, a pure proof-of-work 10 BPS consensus constitutes a qualitative upgrade to Kaspa’s consensus engine, it ranks high in the ordered list of the value propositions of our money (refer further to Michael’s braindump, <a href=\"https://x.com/MichaelSuttonIL/status/1905387292853703157\">https://x.com/MichaelSuttonIL/status/1905387292853703157</a>). Whether the timing of the trouble in Terah’s family has to do with this “mainnet launch” is left to the reader as an exercise.</p><p>Alongside Michael, (and the symbolically-pseudonymous @someone235), another magician, a truly pseudonymous contributor @coderofstuff_ took ownership, and I wish him or her to remain faceless throughout our adventurous journey to silverness.</p><h3><strong>Kaspa Terah</strong></h3><p>The mainstream libertarian vision of governments expects their intervention when the need to break monopolistic entities arises, particularly those whose existence hinges on uneven grounds and structured leverage. Drawing the relevance of this axiom to the context with which this blogpost started is, too, left to the reader’s imagination.</p><p>Trust me, don’t trust me. As promised, it is very difficult to save the ouroboros creature. If I have disappointed you, perhaps you shouldn’t have appointed me in the first place. If you wished for the masks to remain, I have merely pointed at the faces overseeing the masquerade.</p><p>*<a href=\"https://www.youtube.com/watch?v=y1SeStQ1g4Y\">https://www.youtube.com/watch?v=y1SeStQ1g4Y</a></p><p>[1.] I’m not hinting that this is not unrelated to the current maintainers being Canadian and Australian.<br />[2.] For now.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5f100e0555a4\" width=\"1\" />",
    "author": "Yonatan Sompolinsky",
    "published": "2025-04-04",
    "ingested_at": "2025-07-01T11:17:25.455260",
    "source_type": "medium_rss",
    "rss_url": "https://hashdag.medium.com/feed"
  },
  {
    "title": "Kaspa where to (Part IV, last)",
    "link": "https://hashdag.medium.com/kaspa-where-to-part-iv-last-c68717a8d309?source=rss-400d0e2aab3b------2",
    "summary": "<h3>A Kaspa where to (Part IV, last)</h3><p>Exciting times for Kaspa!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/949/1*mTq1rBuZXI6eY2Id2coALw.png\" /></figure><p>Kaspa is gaining traction, more eyes on us, different edges, intentions, interests. These interests may be at odds, but we are very early in our growth path, still categorically a positive-sum game. <br />In particular, future arrival of ASICs will be an overall positive for Kaspers, GPU miners included, similarly to GPU miners’ arrival being a big win for the CPU miners which they outmined.</p><p>Decentralization has more to do with the openness, permissionless, level-field nature of the market rather than the degree of heterogeneity in outcome. Fewer entities dominating mining is not inandof itself a sign of centralization, as long as they are unable to impose nonlinear rich-get-richer effects; for an example of the latter in longest-chain consensus, see Theorem 4 in <a href=\"https://www.ifaamas.org/Proceedings/aamas2015/aamas/p919.pdf\">https://www.ifaamas.org/Proceedings/aamas2015/aamas/p919.pdf</a></p><p>We are all romantically biased towards a visually egalitarian hashrate distribution pie-chart (a sentiment which leads many, in sociopolitical contexts, to wrongly expect fair systems <a href=\"https://www.aei.org/carpe-diem/thomas-sowell-on-the-fallacy-of-equal-outcomes/\">to demonstrate equal outcomes</a>). And, admittedly, capital itself is a barrier-to-entry and brings about some non-linearity to the game. However, this is the price of victory, paid by each and every ecosystem when passing the tipping point.</p><p>Moreover, Kaspa uniquely requires CapEx-heavy mining to fulfill its vision, as will be explained shortly. And so, when time comes and Kaspa shifts into “heavy” mining, we will welcome its maturity phase with great satisfaction, albeit a tinge of sadness.</p><h3>On Kaspa and CapEx</h3><p>(A previous post on this topic: <a href=\"https://hashdag.medium.com/in-which-i-have-no-patience-to-wait-til-by-and-by-b79ce53726b3\">https://hashdag.medium.com/in-which-i-have-no-patience-to-wait-til-by-and-by-b79ce53726b3</a>):</p><p>Kaspa perfects the consensus layer, primarily in terms of speed of confirmation; secondary — throughput capacity, decentralization; down the pipeline — MEV resistance.</p><p>Speed of confirmation is contingent on the mining market being illiquid, since in liquid mining environments, 51% attackers are theoretically — and, in low marketcaps, practically — feasible, and can be fended away by waiting time (or/and finality gadgets) and not by num of confirmations.</p><p>Typically, liquid vs illiquid is characterized by GPU vs ASIC, more inherently it is OpEx vs CapEx. The more CapEx will dominate mining costs, the less feasible it’d be for an attacker to rent temporary hashrate, eg via NiceHash; currently, about 5.3% of Kaspa network is NiceHash-able, and so we are seemingly still in safe illiquid territory.</p><p>CapEx-heavy mining is also more efficient (aka “energy efficient”), as a smaller fraction of the security budget is burnt with every new block. This efficiency is important both for the deflationary (no KAS minting) phase of Kaspa, but mainly for addressing the wastefulness of mining heads on, which is imperative if we are to aim at mass adoption. Notwithstanding the <a href=\"https://twitter.com/nic__carter/status/1481654012772372498?t=kxCxqpNm6q_5uui48Y5Cdg&amp;s=19\">good arguments</a> defending the energy consumption dynamics of POW, in its current form, POW is politically infeasible, and adoption considerations should supersede fundamentalism. <a href=\"https://twitter.com/musalbas/status/1359972560738406401\">https://twitter.com/musalbas/status/1359972560738406401</a></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*DdHvPwKpkXaj-2zfFt6Neg.jpeg\" /></figure><p>All in all, CapEx-heavy mining is essential for virtually instantaneous confirmation times in permissionless consensus, thus for Kaspa to fulfill Satoshi’s p2p electronic cash vision.</p><p>Note: Indeed PoS is pure CapEx, but the security considerations at the limit itself are non-continuous — a system with epsilon OpEx behaves materially differently than one with 0 OpEx, as the latter requires internal, state-dependent Sybil protection whereas the former hinges on external sources to distribute voting power.</p><h3>Optical POW</h3><p>Optical computation is a technology that utilizes interactions of photons, rather than electrons, to process computation. Optical POW (OPOW), envisioned by Michael Dubrovsky, is a POW-function optimized for optical machines. The low energy consumption would render OPOW extremely CapEx-heavy, and would thus be ideal for Kaspa, following above reasoning.</p><figure><img alt=\"An OPOW miner prototype; from the original OPOW paper\" src=\"https://cdn-images-1.medium.com/max/421/1*etQdhJOVXkNK91u2-vb2pQ.png\" /></figure><p>The current POW-function of Kaspa, kHeavyHash, is already friendly to optical ASICs (it is, of course, computable by CPUs, GPUs, and regular ASICs too!). This function can probably be further optimized, more R&amp;D is needed here.</p><p>For the original OPOW paper see <a href=\"https://arxiv.org/abs/1911.05193\">https://arxiv.org/abs/1911.05193</a>; for a recent Stanford lab paper on OPOW see <a href=\"https://techfinder.stanford.edu/technology_detail.php?ID=44752\">https://techfinder.stanford.edu/technology_detail.php?ID=44752</a></p><p>OPOW is a decentralizing force. It levels the mining field by centering competition around capital rather than energy, the former being order-of-magnitude easier to transport, convert, and distribute.</p><p>Aside from geographical decentralization, the low-carbon signature additionally allows for stealth mining operations, the existence of which is essential for censorship resistance (recall <a href=\"https://www.coindesk.com/business/2022/08/21/can-ethereum-fight-back-against-the-uss-sweeping-censorship-attempt/\">Ethereum’s OFAC-compliant</a> effective censorship of Tornado Cash transactions).</p><p>AFAIK optical ASICs will not enter the game in the short-to-mid term, pace depends on R&amp;D efforts and funding, which is fortunately above my paygrade (and I will obviously have no dog in this fight). Nevertheless, it is important to recollect and reaffirm the original vision we had when choosing Kaspa’s kHeavyHash, and to ensure community alignment around this.</p><p>Changes to the current version of kHeavyHash are probably necessary in order to optimize for OPOW, ideally parameter adjustments only, and with reasonable heads up to the mining community. Governance of such changes is TBD, and will depend on whether and how we can avoid centralization on the manufacturing end. This way or another, optical tech initiatives should be first citizens in Kaspa colony, as they are vital for a p2p electronic cash system to scale up while maintaining Satoshi principles, efficient security budget, geographical decentralization, political feasibility.</p><p>TLDR; Kaspa operates at the speed-of-light.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c68717a8d309\" width=\"1\" />",
    "author": "Yonatan Sompolinsky",
    "published": "2023-05-03",
    "ingested_at": "2025-07-01T11:17:25.455286",
    "source_type": "medium_rss",
    "rss_url": "https://hashdag.medium.com/feed"
  },
  {
    "title": "Kaspa where to (Part III)",
    "link": "https://hashdag.medium.com/kaspa-where-to-part-iii-72ddd0bbe6ae?source=rss-400d0e2aab3b------2",
    "summary": "<p>Sharing below quick thoughts on development funding models and sustainability, and on the next grant request, with the hopes that my incentive biases do not contaminate my thought process too much:</p><ol><li>DAGKNIGHT (DK) was an academic effort by Sutton and myself, conceived on the New Year of Trees,¹ and released to the open three years later, on the 14th anniversary of Satoshi’s WP release. As its birth-givers, we obviously wish to observe its impact on real world systems, and it doesn’t get more real than Kaspa. The protocol still requires some (presumably, our) attention before standing on its own feet, and we detailed the main TODOs in <a href=\"https://github.com/kaspanet/kips/blob/master/kip-0002.md\">KIP #2</a>.</li><li>One operation mode would be to work on this for the sole sake of bringing our research into fruition, in “weekend project” mode, with no other incentive in play. This path is perhaps the default one in the gift culture of open-source, indeed one which DAGlabs RIP converged on when releasing Kaspa mainnet with neither a premine nor a heads-up on mining nor any founders’ rewards or the likes.</li><li>Another operation mode, popularized by <a href=\"https://gitcoin.co/\">Gitcoin</a>, is to receive a grant from the community in exchange for code contribution, occasionally with some milestones or/and timeline commitment. This mode is the prevailing custom in Kaspa community, and accordingly we are publishing today a grant proposal. The grant request is for 70 MKAS, which is ~0.5% of the circulating supply. For comparison, the previous funded grant was 100 MKAS, which was ~1% of the circulating supply.<br />My thought process here is to consider a hypothetical senior software engineer, Alice, with relevant domain expertise. When planning her path forward, Alice will seek either stability or opportunity, and in particular will typically not consider a short-term day-job for the same paycheck she’d receive for a long-term one. With this in mind, it makes little sense to denominate in USD deep-tech Kaspa grants (instability), rather they should be expressed in KAS terms (opportunity).<br />The same mental mode was behind the denomination of the previous grant in KAS, which was at the time greatly off the ballpark salary for the relevant devs. Hence the KAS denomination of this grant proposal too. The 0.5% ask seems reasonable to biased-me, especially when benchmarked against the previous grant.</li><li>The community accepting the grant is by no means a necessary condition for having DK implemented on Kaspa — Sutton and I will attempt at implementing it regardless, since, again, there exists already a non-materialistic incentive for us to do so. However, since we are not saints, this will be done on our spare time with non-committal or unspecified timeline.</li><li>A third operation mode, which too exists in open-source environments, is to found a for-profit enterprise around an open-source layer, which naturally incentivizes the entity to allocate resources to further development of the kernel. E.g., IBM’s symbiotic relationship with Linux. This path has the highest potential for long-term sustainability, though, of course, a for-profit entity would have its own priorities, and thus the timeline for DK execution would remain equally ambiguous.<br />I imagine this model could more realistically materialize around smart contracts, which are in arm’s reach from financial innovation opportunities. In contrast, DK is strictly an infra development, and has little to do with the app layer.</li></ol><p>[1] More on trees’ new year <a href=\"https://en.wikipedia.org/wiki/Tu_BiShvat\">here</a>. We submitted a JIP to upgrade this holiday and include DAGs, but the committee couldn’t reach consensus.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/960/1*OtAOvUQWxyHVhk_XAZg57Q.jpeg\" /></figure><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=72ddd0bbe6ae\" width=\"1\" />",
    "author": "Yonatan Sompolinsky",
    "published": "2022-12-14",
    "ingested_at": "2025-07-01T11:17:25.455302",
    "source_type": "medium_rss",
    "rss_url": "https://hashdag.medium.com/feed"
  },
  {
    "title": "Kaspa where to (Part II)",
    "link": "https://hashdag.medium.com/kaspa-where-to-part-ii-c080bcef2f3a?source=rss-400d0e2aab3b------2",
    "summary": "<ol><li>Crypto winters are warm for projects with character.</li><li>Last month Michal Sutton and I published the <a href=\"https://eprint.iacr.org/2022/1494\">DAGKNIGHT</a> protocol (DK), which to the best of our knowledge is the first POW consensus protocol that is responsive to the network’s actual (*adversarial) latency while being resilient to 49% byzantine attackers. DK is the culmination of nearly three years of research, a period in which we weren’t at all sure if the aforementioned property is at all possible to achieve.¹</li><li>Some work still needs to be done before considering DK for Kaspa:<br /> <br />(i) Completing several missing details in the proof section.<br /> <br />(ii) Preparing the paper for peer-review (depends on conference target).<br /> <br />(iii) Devising efficient algorithms — the current pseudocode is highly inefficient, as it was optimized for ease of reasoning rather than real world implementation.<br /> <br />(iv) Adapting the consensus algorithm to meet additional requirements of an actual cryptocurrency, e.g., the need to regulate minting, control difficulty, and enforce pruning, all of which require a responsive synchronous protocol (rather than DK’s partially synchronous operation mode).</li><li>Similarly to GHOSTDAG, DK enables high bps (blocks per second), just with much faster confirmation times. Some research needs to be done in order to suggest the optimal bps — increasing the rate indefinitely doesn’t necessarily shorten confirmation times, as it increases the higher relative latency or DAG width. The increase is both due to more blocks created per second and due to these blocks’ headers being larger. Regarding the latter factor, one can envision a scenario where confirmation times improve by reducing the number of block references inside a block (either in consensus or as a default mining rule), but whether or not this is the case is pending further research.</li><li>DK enables additional features, on which more research is needed.<br /> <br />(i) One example that comes to mind is <a href=\"https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-May/008017.html\">flexcaps</a>, a proposal to allow miners to create blocks of different sizes and difficulties. While proposed originally for Bitcoin, at high block rates flexcaps require the DK consensus. To see the connection, observe that larger blocks → higher propagation delay of blocks → more blocks created in parallel → wider DAG; and the DK protocol uniquely does not need to bound in advance the width of the DAG, and can cope with it varying even across short timespans. One motivation for flexcap is to support, in times of peak demand, a higher throughput than that which the system can support on average. Indeed, large blocks consume both instantaneous load on the system (CPU, network congestion, etc.) and an accumulating load (larger UTXO → higher RAM and disk I/O for later block processing), which justifies a gap between the maximum limit on resource consumption and the average one.² This gap is enabled through flexcaps (or through the similar <a href=\"https://bitcointalk.org/index.php?topic=1078521\">elastic block cap proposal</a>).<br /> <br />(ii) Another potential feature is the <a href=\"https://github.com/kaspanet/research/issues/1\">stealth txns</a>, a construction which <em>utilizes</em> the asynchrony caused by high bps to protect users from MEV (relevant when smart contracts will be developed). More generally, and still in the context of MEV, the fact that many miners can create a block in the “next round”, can be utilized to facilitate richer transaction fee mechanisms, in some resemblance to Flashbots’ recent <a href=\"https://writings.flashbots.net/the-future-of-mev-is-suave/\">SUAVE</a>.</li><li>Similarly to the <a href=\"https://github.com/kaspanet/kips/blob/master/kip-0001.md\">Rust upgrade</a>, this consensus upgrade will require a new grant request from the community. A suggested scope and raise amount will follow. I hope miners and other Kaspa whales will find this initiative as desirable and long-term profitable as the previous grant. Our community is evergrowing in size and interests, and raising large funds in the future might become harder and harder, at which point we will need to find other structures to maintain development. Hopefully we haven’t reached yet the tipping point.</li><li>Speaking of community size, a Discord moderator pressed a wrong button this week and accidentally kicked out all inactive users from the server, reducing Kaspa Discord community (~12k) by about 25%. The good news is that we learnt that ~9k members were apparently active in the last 30 days, which speaks volume of the quality of the community.</li><li>In the spirit of thanksgiving, I am grateful to all 9k of you for turning Kaspa from a sound protocol to a sound money.</li></ol><p>[1] More accurately, one of us was positive throughout that a possibility is within a hand’s reach, and the other was skeptic and believed an impossibility result was lurking in the dark. Interestingly, the roles reversed with respect to the question whether Kaspa can take off. We swore not to reveal the corresponding identities of the weak in faith, but the reader can be assured that between the two of us the truth always lies.</p><p>[2] In Bitcoin, where there’s no pruning of historical data, the gap is even larger, due to initial blockchain download that full nodes go through by default when onboarding.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c080bcef2f3a\" width=\"1\" />",
    "author": "Yonatan Sompolinsky",
    "published": "2022-11-26",
    "ingested_at": "2025-07-01T11:17:25.455314",
    "source_type": "medium_rss",
    "rss_url": "https://hashdag.medium.com/feed"
  },
  {
    "title": "Kaspa where to (Part I)",
    "link": "https://hashdag.medium.com/kaspa-where-to-part-i-ce6a1a2c8eb0?source=rss-400d0e2aab3b------2",
    "summary": "<p>This is a concrete version of a longer post which I started writing but had too much spare time so didn’t complete yet.</p><p>Context: One of Kaspa’s core devs, Michael Sutton, suggested a plan to order-of-magnitude enhance Kaspad full-node performance by refactoring the codebase and rewriting it in Rustlang. (<a href=\"https://discord.com/channels/599153230659846165/844142778232864809/993245032670842991\">https://discord.com/channels/599153230659846165/844142778232864809/993245032670842991</a>)</p><p>My twosats on the matter:</p><ol><li>Kaspa was initialized as a live proof of an idea, a demonstration of a novel (and very cool, but that’s beside the point) paradigm for permissionless consensus. In bootstrapping Kaspa, I was fully aware that we do not have the resources — or the manpower — or the organization machinery — required to unlock even 5% of Kaspa’s potential, and that some external strategic move will need to happen for that aspiration to come true (think Project Serum and Solana <a href=\"https://defirate.com/ftx-serum-solana/\">https://defirate.com/ftx-serum-solana/</a>).</li><li>For these reasons, as Kaspa OG’s recall, <a href=\"https://hashdag.medium.com/kaspa-launch-plan-9a63f4d754a6\">I considered launching</a> Kaspa in testnet mode, then opted for a novel (aka failed) mode, which I coined “gamenet”, and which can be thought of as “testnet with incentives”. While this attempt was apparently naïve and, in retrospect, flawed I am mentioning it to recollect the mindset with which Kaspa was released. (For the same aforementioned reasons I kept myself uninvolved with the exchange listing efforts of Kaspa; I fully appreciate their value to the community, and at the same time I preferred erring on the side of caution).</li><li>I agree with concerns voiced by some community members that, in principle, to bring real value efforts should be focused on integration, adoption, marketing, etc. In particular, at this stage, high bps and high tps are imho not a meaningful step towards building a non-hypothetical financial system.</li><li>However, our community is still far from the scale and organization necessary to reach actual adoption, if not merely for its still modest treasury size (which is contribution-based, and managed by a few volunteer OG’s). With that in mind, I believe the most correct usage of the funds donated by miners is to continue the path of demonstrating live the original DAG vision, by improving the base layer node and later on perhaps upgrade its consensus; which is precisely the proposal put forward.</li><li>The current Kaspad codebase is an adaptation of the Bitcoin client btcd, written in Golang. It enjoys a fine amount of technical debt and great code complexity, which make it difficult for new folks to contribute. The proposed refactoring explicitly aims at writing the codebase in a modular and legible manner, which is arguably even more important than performance enhancement.</li><li>For full disclosure, I am working tightly with Sutton for a few years now, and am highly biased in favour of any R&amp;D task or project to which he dedicates his rare talent (cf. Proverbs 27:14). Him availing a few months’ of his full capacity to Kaspa is exceptional, and I hope the community (and esp. miners) will match this generosity. I believe a ballpark of 1% of the circulating supply would be very reasonable.</li></ol><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ce6a1a2c8eb0\" width=\"1\" />",
    "author": "Yonatan Sompolinsky",
    "published": "2022-07-05",
    "ingested_at": "2025-07-01T11:17:25.455326",
    "source_type": "medium_rss",
    "rss_url": "https://hashdag.medium.com/feed"
  },
  {
    "title": "Kaspa (Black Tuesday)",
    "link": "https://hashdag.medium.com/kaspa-black-tuesday-8c7f4fa35834?source=rss-400d0e2aab3b------2",
    "summary": "<p>This post assumes reader context on the crash of the Kaspa network in the course of the last 48 hours, and provides some additional notes and perspective.</p><p>(1) To simplify logic and debugging, and since the gamenet concept didn’t really catch air, I removed the random block reward and replaced the average block reward of 500 with a deterministic block reward of 500. Thus, if so far we mined <strong>on average</strong> 86400x500=43200000 Kaspa per day, we will henceforth mine <strong>deterministically </strong>86400x500=43200000 Kaspa per day.</p><p>(2) Many ppl expressed their concern about the future rebase that will take place soon. I want to reiterate that the rebase is cosmetic only, it’s a rename, an altering of representation. If you mined so far, say, 10% of the (total or of the circulating) supply of Kaspa, you will posses 10% after the rebase as well.</p><p>(3) The deflationary monetary policy HF that I mentioned here (https://discord.com/channels/599153230659846165/909907923084382218/911015904144420895 or <a href=\"https://hashdag.medium.com/kaspa-launch-plan-responding-to-reality-6b4bec449037\">https://hashdag.medium.com/kaspa-launch-plan-responding-to-reality-6b4bec449037</a>) will be specified next week, after syncing and mining resume for a few days, the network remains fully operational and confident, and the voluntary Kaspa magicians (Ori, Michael, Elichai) get some sleep and catch up with their own research and ventures.</p><p>(4) The community by and large reacted solidly to the crash. Thank you! No-one took it lightheartedly, and at the same time most focus was on providing datadirs and other useful info, getting instructions, funny memes. Let’s hope we won’t need to test ourselves again in similar circumstance.</p><p>(5) There was some genuine misunderstanding regarding the approaches we were looking into. Specifically, we were never considering a rollback in the sense of pointing at an early state which we were satisfied with and wanted to revert to, and discarding blocks and transactions appended to it later. Rather, we were searching for the <em>latest</em> state for which we have a <em>certainly-valid</em> UTXO commitment. While many users shared with us up-to-date datadirs, and while we had our own datadirs, we had to spend effort and time to ensure that the UTXO commitment builds correctly. Thus, we (read: aforementioned devs) had to rebuild the state afresh, feed it with such datadirs, and compare the commitments. Fortunately, the UTXO that we built hashed into the same UTXO commitment string embedded in the latest block in the datadir, producing 710f27df423e63aa6cdb72b89ea5a06cffa399d66f167704455b5af59def8e20, which proved that the DAG UTXO algebra was not erroneous, but “merely” a victim of the memory problem. This is not to say the architecture of this module should not be revised and improved — -a more correct architecture would protect it from DB failures.</p><p>(6) Kaspa is here to stay, in case you were wondering.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=8c7f4fa35834\" width=\"1\" />",
    "author": "Yonatan Sompolinsky",
    "published": "2021-11-23",
    "ingested_at": "2025-07-01T11:17:25.455337",
    "source_type": "medium_rss",
    "rss_url": "https://hashdag.medium.com/feed"
  },
  {
    "title": "Kaspa launch plan (responding to reality)",
    "link": "https://hashdag.medium.com/kaspa-launch-plan-responding-to-reality-6b4bec449037?source=rss-400d0e2aab3b------2",
    "summary": "<p>First and foremost I wanted to thank you all for joining and forming this community, for the interest, excitement, and involvement around the project. Seeing my PhD obsession — POW DAG consensus — realize itself into a live network and a spontaneous community is thrilling yet humbling. Thank you, <em>Todah</em>!</p><p>I’m definitely going to start valuing members-count over citation-count, so please bring more crypto friends to the party!</p><p>Every few years a new fair-launched POW cryptocurrency captures the excitement of the community — Litecoin, Monero, Grin, and now Kaspa. May the force be with us.</p><p>Since we didn’t anticipate this rapid growth, I didn’t prepare accessible answers to several FAQs. I hope to write a longer post about all this in the coming days, but for now here are some answers:</p><ol><li>Monetary policy will be deflationary. Halving will be more aggressive than Bitcoin’s since market conditions are different (order-of-magnitude faster market discovery). When the deflationary scheduling will be activated, and what would be the initial block reward (compared to the current avg of 500) — TBD. We will try to seal this next week or so. These numbers will imply the finite cap on supply. BTW we should rebase the term Kaspa to refer to today’s 1000 Kaspa, say; the current representation feels not so scarce :)</li><li>Our proof-of-work is a Kaspa variant of heavy-hash, let’s call it k-heavy-hash. My goal here was to create a CapEx heavy POW function, since I believe this concept is both energy-efficient and provides more miner-commitment (stronger than ASIC since less OpEx burnt). Whether k-heavy-hash is actually CapEx heavy, and whether a different POW function will better serve this goal for Kaspa — is a question I’m open to discuss.</li><li>The project is maintained by a few devs, all of which have other full time dealings, and some of which are funded by DAGlabs (but totally self managed). In particular, there’s no company or entity behind the project that is responsible for your wallet, full node, funds, miners. We are here during our spare time. I, for one, am a full time postdoc at Harvard university, and while this project is my PhD baby, I am at the same time dedicated to my postdoc baby. So this is a purely community project, please take that into consideration. What can you do to help? Arrange for more dev-power to learn the codebase and join the efforts; DAGlabs can potentially fund additional devs, as long as they have the ability to manage themselves, open issues, fix bugs, manage PRs, etc.</li><li>Roadmap. There is no official roadmap as there’s no organized development. I can write down what devs should be working on IMO, post bug fixing and version updates (HFs). In short, IMO priorities should be accelerating <em>gradually</em> to 10 blocks per second, then implementing an amazing upgrade to the consensus protocol, pending theoretical research results of Michael Sutton. In parallel, if someone can promote a privacy gadget (e.g., bulletproofs) and implementation for Kaspa that would definitely leap us forward.</li><li>Next week there will be a hard fork (HF) in order to fix a bug and decrease header size. Tune in on this, especially if you are running a mining full node. A few weeks later there will be a HF to embed said monetary policy.</li><li>Will we list the coin on exchanges? There is no “we”, there’s “you”. And I suggest waiting for the community to grow more organically before bringing retail.</li><li>When is it recommended to stress test for utxo throughput? You are free to stress test as you wish. However, note that even if bugs are discovered, some time will pass before the devs can make themselves available to fix them. Therefore, I suppose better wait for the current system to prove itself stable for more than two weeks, say.</li><li>What about block explorer? I believe next week devs will deploy one.</li><li>Feel free to follow me here or on Twitter <a href=\"https://twitter.com/hashdag\">https://twitter.com/hashdag</a> where I hope to post more Kaspa related material in the coming weeks.</li></ol><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6b4bec449037\" width=\"1\" />",
    "author": "Yonatan Sompolinsky",
    "published": "2021-11-18",
    "ingested_at": "2025-07-01T11:17:25.455347",
    "source_type": "medium_rss",
    "rss_url": "https://hashdag.medium.com/feed"
  },
  {
    "title": "Kaspa launch plan",
    "link": "https://hashdag.medium.com/kaspa-launch-plan-9a63f4d754a6?source=rss-400d0e2aab3b------2",
    "summary": "<h3>Kaspa launch plan (proposal)</h3><p>tldr</p><ul><li>launch Kaspa in gamenet mode, a research oriented experimental network</li><li>inject deliberate fragility into Kaspa launch via random semi-scarce monetary policy</li><li>construct battlefield for reward-based and MEV-based reorgs</li><li>as community matures and hashrate grows, go full scarcity mode, transition from game- to main- net mode, rendering early (gamenet) stage miners profitable in retrospect</li><li>gamenet 2.0 requires developing Ethereum bridge to simulate and practice MEV-reorgs, in order to test and demonstrate DAG consensus’ antifragility</li></ul><h3>Why Kaspa shouldn’t launch as an ordinary cryptocurrency</h3><p>[L1, POW, lack of EVM]</p><p>There seems to be little room now for a new L1, especially one powered by PoW such as Kaspa. The market has matured, and with it the scope of attacks and manipulations has expanded from direct attacks on block ordering (eg double spends via reorgs, liveness attacks) to attacks that regard txn content — typically in the zero-to-one-confirmations phase — by miners or bots (aka flashbots). Moreover, Kaspa lacks as of now EVM support, rendering it significantly less relevant to the current market.</p><h3>Gamenet: A proposal to launch Kaspa in a novel experimental mode</h3><p>Kaspa may be launched as a research-oriented consensus engine that is focused on experimentation, novel testing of dynamics, and a vibrant battlefield for real world cryptoeconomics attacks. I call it gamenet mode.</p><h4>Cryptoeconomics phase 1</h4><p>[CPU/GPU mining, uncertain scarcity, low hashrate and security, non-commercializable]</p><p>The platform should be CPU/GPU-mineable, to facilitate the base activity; I believe Ethash is a neutral candidate that fits our needs. However, its token should be deliberately unfit for commercialization, in order to penetrate hardcore communities, individuals, and zones that refrain from cooperating with non-BTC or non-ETH tokens. Accordingly, the token’s supply should challenge the ordinary notion of scarcity, and should be unfit for exchange listing. This implies that the platform will obtain low hashrate and low security, at the initial stages.</p><h4>Gamenet activity</h4><p>[battle-field, simulation, real world game, selfish mining, reorgs, MEV]</p><p>The theme of gamenet’s activity can be thought of as a continuous hackathon over a live network which serves as a battle-test field for simulating real world attacks, manipulations, and dynamics of a multi-player network. The block rewards will incentivize occasional reorg/selfish-mining attacks by strategic and sophisticated miners of the gamenet, whereas transactions in the network will implicitly or directly reflect MEV exploits from real world DeFi systems such as Ethereum.</p><h4>Community</h4><p>[R&amp;D groups and individuals, testbed for innovation, recognition by broad crypto community]</p><p>The goal is to attract research and dev groups (e.g., flashbots fans) to play, compete and/or collude over the live system, and to extract insights on the real-world dynamics of other live systems such as Ethereum. Further, commercial L2 projects that propose solutions to certain exploits, such as using cryptographic primitives for MEV, can implement those over Kaspa gamenet and prove the robustness of their solution, while others may attempt to refute it. I hope Kaspa will become a center of a vibrant R&amp;D community, and that the general community will look to Kaspa gamenet as a credible source of insights regarding cryptoeconomic dynamics in the wild.</p><p>An example for the community’s interest around the topic may be found in this recent summit <a href=\"http://reorg.wtf/\">http://reorg.wtf/</a></p><h4>Cryptoeconomics phase 2</h4><p>[monetary policy solidification, recover scarcity, compensate early community]</p><p>As the community and the platform matures, we will want to transition to a solid monetary policy, regulate the supply, and trade over exchanges. To this end, we may set an automatic trigger in consensus that will eliminate the randomness in the monetary policy, and the uncertainty of the supply, once a certain hashrate is reached. This will automatically compensate early participants — the early miners of the network — by rendering the mined tokens scarce in retrospect. See below for specifics. See <a href=\"https://fc21.ifca.ai/papers/222.pdf\">https://fc21.ifca.ai/papers/222.pdf</a> by Lucianna Kiffer for a related design.</p><h3>Kaspa development and support</h3><p>[community+product management, further development and support]</p><p>As a continuous real-world hackathon, Kaspa gamenet can significantly enjoy some product and community management, conveying and demonstrating to the community the rules of the game and example dynamics. Community members are welcome to take the lead on these fronts.</p><p>On the development side, and closer to the backend, explicit MEV activity can be simulated via a bridge from Ethereum. While not necessary for gamenet, I believe gamenet+MEV will make the platform much more attractive a battle-field.</p><p><em>Individuals capable and willing to take upon themselves some of these efforts, and who require funding, may DM me.</em></p><h3>Timeline</h3><p>[Kaspad ready mid October, Kaspa launch end of October, full gamenet activity TBD]</p><p>Kaspad — the core consensus component of Kaspa — will be production ready (though untested) by mid October. The remaining features are (1) implementation of the monetary policy described below, (2) plugging in the chosen PoW function.</p><p>The execution of components that enhance gamenet activity depends on community engagement.</p><h3>Monetary policy and block rewards</h3><h4>Requirements</h4><p>The block reward should incorporate randomness so as to:</p><ol><li>Test selfish mining and reorg attacks,</li><li>Introduce uncertainty regarding the supply,</li><li>Incentivize extending the main chain, 95% of the time (say),</li><li>Incentivize forking the chain when the reward — or the MEV opportunity — is exceptionally high.</li></ol><h4>Concrete proposal</h4><p>Have each block mint a random amount of Kaspa, where the randomness is a function of the last $M$ blocks. The result of the randomness, the “sampling”, should depend on the block’s hash, to ensure that it cannot be gamed. The randomness should not be a function of the previous block only ($M=1$) because that will lend itself to frequent forking attacks. At the same time, it should be responsive to recent blocks, to ensure a sufficient degree of uncertainty with respect to the supply (so $M=10¹²$ won’t do, as well). I propose $M=~100$ blocks.</p><h4>Formal description</h4><p>Given a DAG $G$, GHOSTDAG outputs a chain $C(G) \\subseteq G$. For each block $B ∈ G$, let $merging(B)$ be the earliest block in $C(G)$ that contains $B$ in its past. For each block $B ∈ G$, $B.selectedParent$ is the tip of the chain $C(past(B))$. For each block $B ∈ G$, $mergeSet(B,G)$ is defined as $past(B)∖ past(B.selectedParent)$ if $B$ is in $C(G)$, and the emptyset otherwise.</p><p>The reward of blocks in G, $rew(*)$, is defined by:</p><ul><li>$rew(genesis) = const_1$</li><li>$rew(B) = const_2*avg_{D \\in prvs M blocks of B}rew(D)*4^x + const_3*sum_{D\\in mergeSet(B)}(rew(D))$</li></ul><p>where $x$ is a random variable drawn from the normal distribution (mean 0, std 1), and which is uncontrollable by the miner (it is the result of the block hash). $const_1=1$, and $0&lt;const_2,const_3&lt;1$ should be in the order of $0.9$ and $0.1$ respectively; $M$ should be in the order of 100 as mentioned.</p><h4>Hashrate trigger</h4><p>Once the network reaches a meaningful hashrate, one that corresponds to operational expenses of $I=250k USD$ per week (say), the randomness should be eliminated, and then each block should mine a block reward of $rew(B) = const_3$ (const_3=1, say). This could be triggered automatically in consensus and requires no soft/hardfork.</p><h4>Finality parameter</h4><p>In phase 1, due to the expected low security, the finality parameter of the system should probably be set to be in the order of minutes rather than hours. In case of netsplits, the conflict should be resolved manually, which is a legitimate practice in a non-mainnet platform.</p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9a63f4d754a6\" width=\"1\" />",
    "author": "Yonatan Sompolinsky",
    "published": "2021-09-22",
    "ingested_at": "2025-07-01T11:17:25.455357",
    "source_type": "medium_rss",
    "rss_url": "https://hashdag.medium.com/feed"
  },
  {
    "title": "In which mayday mayday we are syncing about*",
    "link": "https://hashdag.medium.com/in-which-mayday-mayday-we-are-syncing-about-bf05ad58957a?source=rss-400d0e2aab3b------2",
    "summary": "<h3>Don’t trust, terrify!</h3><p>The “don’t trust, verify!” slogan is beyond my comprehension. I board airplanes without verifying anything about the pilot or the aircraft; I visit restaurants and foolishly eat — without verifying what will be transmitted to my blood; I take medicines without verifying the supply chain. Why would I protect my money with measures I am not taking to protect my life?!</p><p>This reminds me of Jacob, the forefather of Israel, who crossed the Jordan river some 35 hundred years ago, back to his homeland. Albeit, he forgot a few small pitches (think of dust UTXOs), so we are told by later Talmudic Rabbis, and so he went back to the eastbank, in the middle of the night, alone, to fetch the pitches. This was apparently unsafe, and he met a mysterious figure who wrestled with him, a battle from which he came out with a limp, a divine blessing, and a new name — Israel. The Talmud concludes:</p><p>“ <em>From here it is derived that the possessions of the righteous are dearer to them than their bodies. And why do they care so much about their possessions? It is because they do not stretch out their hands to partake of stolen property.</em> “</p><p>I hope the connection between this story and SPV sync mode based on multiplicative-hash UTXO-commitments is self explanatory but, just in case, do note that verifying by yourself the proper functioning of all external systems which you rely on is infeasible, unscalable, and anticivil — civilization is the scaling up of function and trust — whereas doing so only with respect to money is peculiar and will cause you to limp.</p><h3>Why not fiat?</h3><p>Because fiat supply is inflated unpredictably; because the political printing of money is corrupting the democratic sphere, positing the political debate on allocation of money instead of creation of wealth; because regulators are attempting to control financial transfers, eliminate cash, restrict economic freedom.</p><p>We reiterate cryptocurrencies’ golden traits — predictable issuance and censorship resistance. In contrast, the property “no fraudulent transaction ever occurred in this currency system” is not the something (or at least: main thing) users should/care about. Consequently, when joining a cryptocurrency system, checking its issuance and its decentralization is far more important than checking the historical validity of transactions.</p><p>Yes, we go so far as to say that users do/should not care about historical corruption. For the user is interested in knowing that the state of her node is the one that is most likely to prevail by the economic majority, not that the state of her node is the valid one in some abstract sense. <em>The primary goal of consensus systems is facilitating</em> agreement, <em>not enforcing</em> consistency. And if the economic majority happens to follow and maintain a ledger to which an invalid transaction entered at some point in history, so be it, the system can still serve its purpose of facilitating agreement even if its constitution was breached at some point in time. Indeed, if code rules, the constitution, are violated time and again, or even not extremely rarely, the wise user should definitely refrain from joining said network. Users are therefore protected from unsafe networks as long as they can safely assume the existence of efficient ways to communicate and diffuse information on such mishaps. This novel way to diffuse information is called The Internet, or its manual predecessor — Civilization.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*gVeVc_JLtgKMJjQUnviwlA.png\" /></figure><p>As with airplanes and restaurants, users rightly assume that they arrived at a functioning system, and that information on past security breaches would have reached them in the conventional information channels. These information channels are typically reliable thanks to highly-staked, ideological, or philanthropic whistleblowers that continuously verify the ledger — or by previous users that have been harmed by the system’s malfunctioning — granting the system its herd immunity. Running full nodes are thus very important for the ledger’s society, however, the marginal utility is rapidly decreasing.</p><p>To summarize: If you are going to join IOTA network, google it first.</p><h3>Why not Bitcoin?</h3><p>Initial Blockchain Download (IBD) is the process by which new nodes join the network. Since Bitcoin core devs’ ethos is “don’t trust, verify!”, the default behaviour of the new node is to download and verify the entire history of the Bitcoin ledger. Consequently, Bitcoin’s throughput is deliberately limited to enable fast IBD-indeed, processing too many transactions per second today would make it difficult for a user joining in 2040 to verify that today’s transactions were valid. I kid you not.</p><p>Back in 2013 my advisor sent me a paper titled “Bitcoin: a p2p electronic cash system”. The new narrative seems to have changed into “Bitcoin: an electronic store of value” coupled with “the attempt to create a p2p electronic cash coin is a scam”. An interesting development that is.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/623/1*mdRaVUEqfc6uxohppCEKZQ.jpeg\" /></figure><h3>Why Kaspa?</h3><p>First, to make Satoshi great again. PHANTOM is really a neat generalization of Nakamoto Consensus (when k=0 PHANTOM coincides with the longest chain rule), it follows the same principles just with support for concurrency. It is Satoshi at its best, and the only path to fulfil His electronic cash vision. We make DAGs because we know how to and because no-one else does. We implement PHANTOM because we want to ping with “send txn” and be ponged “txn mined” in the same manner we get the results of a google search or send an email. We picked up this challenge in the same way Bitcoin core devs chose to work on Taproot — it is cool and not entirely useless.</p><p>Secondly, to make myself rich.</p><p>Third, because we need a base layer whose tradeoffs are centered around the crypto-informed user’s needs and asks. This implies, in particular, and according to the worldview I suggested above — implementing the default node to skip historical verification, making it an optional operation, one that relies on the fewer archival nodes that some entities choose to maintain and make available (this is the same situation as in Bitcoin, since most Bitcoin full nodes are pruning the data necessary for syncing newcomers, but be advised to not share this info with Bitcoiners, it’s gonna ruin their day and by implication your week). Importantly, these archival nodes maintain the ability to prove to newcomers that a certain transaction was fraudulent, by providing the Merkle witnesses for inclusion in the blocks involved in the claimed collusion.</p><p>Accordingly, Kaspa nodes prune block data by default, and new nodes by default do not request historical data, rather, they sync in SPV mode, i.e., by downloading and verifying only block headers. I reiterate that this is not a stronger trust assumption than a history-verifying node, rather a different requirement. The node then requests the UTXO set from untrusted peers in the network, and verifies it against the UTXO commitment embedded inside the latest received header (technically, this is done against the latest pruning point). If those do not match, the node bans the sending peers, requests the UTXO set from new untrusted peers, and repeats the process. If those match, the node verifies that no unexpected inflation occurred by comparing the sum of UTXOs to the specified minting schedule, a comparison for which block headers suffice.</p><h3>Make Satoshi Great Again</h3><p>My not-novel suggestion to scale up Nakamoto Consensus:</p><ul><li>Latency constraint on Consensus — move from longest-chain to PHANTOM, which is tolerant to and compatible with any predetermined upper bound on the latency.</li><li>CPU consumption — process few transactions per second on L1, while supporting large payloads, which are cheap CPU-wise, and which enable easy and healthy L2 (e.g., SN/TARK proofs for ZKRUs).</li><li>Bandwidth consumption — design sharding of data and data availability proofs, similar to Eth 2.0 stopped after phase 1 (see Ethereum’s <a href=\"https://ethereum-magicians.org/t/a-rollup-centric-ethereum-roadmap/4698\">rollup-centric revisited roadmap</a>); this is an open research question, since PoW has no native identities to serve as the basis for sharding.</li><li>Memory consumption and disk I/O — implement <a href=\"https://github.com/cambrian/accumulator\">class group based accumulators</a> that require no trusted setup, and which allow to prune the UTXO set and run as a stateless client. Challenges include: UX of storing and updating the witnesses; weighing memory save against higher CPU consumption.</li><li>Storage — prune block data, reducing storage requirement from <em>O(block header size)*O(num of blocks in history) + O(block size)*O(size of history)</em> to <em>O(block header size)*O(num of blocks in history) + O(block size)* O(size of pruning window)</em>; additionally, consider pruning block headers, further reducing the requirement to <em>O(block size)*O(size of pruning window)</em>. Pruning block headers is an open research question, since it is then unclear how a new node will be guaranteed it is syncing to the consensus state and not to a stale or malicious branch. However, arguably, any system with (deterministic) finality enjoys/suffers/relies on weak subjectivity, and therefore reading the entire history of PoW might be redundant.</li><li>IBD time — implement DAG-adapted version of <a href=\"https://ieeexplore.ieee.org/document/9152680\">FlyClient</a> to reduce the cost of syncing a new node from O(num of blocks in history) to O(log(num of blocks in history)). This does not reduce the storage at the syncer, but does allow the syncee to sync w/o downloading the entire history of block headers.</li></ul><h3>What are you syncing about?</h3><p>Concluding today’s topic. Kaspa is PoW on steroids. It is optimized for the informed users, not for the ideologs. Its throughput ought be constrained by real time performance considerations, not by the performance of downloading and verifying the historical ledger, which is an auxiliary trust gateway, but not the primary pillar of trust in the system.</p><p>Kaspa should reach 100 blocks per second, and to that end, Kaspa nodes should be pruning data by default. When new nodes join the network, they should sync against the heaviest PoW DAG, as it is the one with max likelihood to represent the current consensus view. Node operators should take measures to connect to sufficiently many peers so as not to be eclipsed from the network (as in Bitcoin), so that they hear about historical mishaps, e.g., invalid blocks, finality violations, etc., which are recorded and propagated by full nodes to ensure that new nodes know what they are syncing about.</p><p>I’m reminded of the very best ad in the history of ads. Pardon my associative memory. The ad is picturing a coast guard trainee on his first day on the job. He’s apparently not too well versed English-wise, which is unfortunate for the desperate pilot trying to communicate with him that the plane is …</p><p>See the ad in the title reference below.</p><p>* <a href=\"https://www.youtube.com/watch?v=yR0lWICH3rY\">Title reference</a></p><p><em>Originally published at </em><a href=\"https://blocklivenessmatters.com/blog/syncing\"><em>https://blocklivenessmatters.com</em></a><em> on May 5, 2021.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=bf05ad58957a\" width=\"1\" />",
    "author": "Yonatan Sompolinsky",
    "published": "2021-05-05",
    "ingested_at": "2025-07-01T11:17:25.455367",
    "source_type": "medium_rss",
    "rss_url": "https://hashdag.medium.com/feed"
  },
  {
    "title": "In which I have no patience to wait ’til by and by*",
    "link": "https://hashdag.medium.com/in-which-i-have-no-patience-to-wait-til-by-and-by-b79ce53726b3?source=rss-400d0e2aab3b------2",
    "summary": "<h3>A personal take</h3><p>Fun fact: Many Bitcoiners believe that Bitcoin’s 10-minute block time is not too slow and that having a fast block rate is not useful.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/596/0*IlBLIc35wJApcYSq.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/598/0*0ORtD7OGWk8ULTUF.png\" /></figure><p>This is a very disturbing stance, since I’ve invested lots of conceptual and practical efforts into accelerating block times based on the premise that fast confirmation times-or “Liveness” in consensus terminology-matters, and it will break my spirit if this proves in vain. It is with the noble objective of making sure I’m needed that I present to you below the case for fast Liveness. I believe it matters.</p><h3>The case against fast confirmation times</h3><p>The elephant in the room: No one needs Bitcoin to be user-friendly; it is here to be HODLed, not used. Bitcoiners rarely pay with their bitcoins, a true Bitcoiner never sells them, and we can all just hope to be as sacred as He <a href=\"https://bitslog.com/2013/04/17/the-well-deserved-fortune-of-satoshi-nakamoto/\">who never even touched his bitcoins</a>.¹</p><p>While obnoxious, this position is not ridiculous. The most difficult part solved by Bitcoin was the creation of a stateless algorithmically-controlled money system. Of course, this money should be transferable and, ideally, conveniently so; but the main achievement is not “good UX money.” And if improving Bitcoin’s UX would compromise its resilience, decentralization, or social scalability, it’s not worth it.</p><p>This position does imply, though, that <a href=\"https://github.com/kaspanet\">a different cryptocurrency</a> will prevail as a cryptocurrency that’s intended to be used by the masses.</p><h3>The case against fast block times</h3><p>If you ever wondered why you are not invited to VIP Bitcoin parties, it’s probably because you let it slip that you think fast blocks are cool, which proves your deep lack of understanding of our cult’s core principles. This is where continuing reading this post can become very helpful for you.</p><p>In order to understand what system parameters improve confirmation times, and when, we need to describe the flow of a crypto payment authorization.</p><p>If you are a merchant receiving payments in crypto, you must wait until transactions are sufficiently irreversible before confirming them to the payers. There are two paradigms on how this <em>waiting</em> is done. In the first paradigm, you wait for a sufficient amount of blocks to pile atop the transaction in the ledger; here, accelerating block liveness will shorten your waiting, namly, the confirmation time. In the second paradigm, you wait for a sufficient amount of (absolute) time to pass before confirming; accelerating block times will not shorten your waiting.</p><p>Essentially, in the first paradigm you wait until enough <em>blocks</em> are mined so that the [hypothetical or invisible] attacker’s chain is shorter than the ledger’s main branch, with sufficiently high degree of certainty; in the second paradigm you wait until enough <em>time</em> passes so that the attacker’s budget has drained. The two paradigms correspond to two threat models.</p><h3>Illiquid vs. liquid mining</h3><p>Bitcoin miners spend only a few 10 5USD/hour on protecting our transactions. Their revenue from mining-a.k.a. the <em>security budget</em>-is on the order of a few 10 6USD/hour. Contrast this with Bitcoin’s market cap of a few 10 11USD, and you’ve got yourself wondering how 10 6can protect a 10 11asset-surely there are ways to make much more than a few millions by attacking the Bitcoin giant, by reversing the ledger after an hour or two. For instance, if you are a financial whale that has the ability to short Bitcoin,² or if your name is Vitalik and you want to double spend bitcoins to keep Bitcoiners from being obsessed with something other than Ethereum’s success. Definitely worth a few billions.</p><p>Well, since the Bitcoin mining market is highly illiquid, an attacker cannot get hold of temporary hashrate even if he has a few spare 10 6USD. Instead, the attacker will need to invest in manufacturing or purchasing mining ASICs, which are priced for long term mining, and are indeed on the order of magnitude of 10 11USD. It is the capital expenditure of Bitcoin miners (CapEx), therefore, that protects our Bitcoin transactions, not their operational expenditure (OpEx). The high CapEx is what lends credence to our assumption that the majority of hashrate is held by honest miners (on which I’ll elaborate below), whereas the OpEx seems too low relative to the potential gain from an attack.</p><p>But many cryptocurrencies operate in liquid mining³ environments wherein significant hashpower is available for temporary rent on <a href=\"https://www.nicehash.com/\">NiceHash</a>; NiceHash is a marketplace for renting hashpower, typically relating to GPU-dominated coins. Now, if attackers can temporarily rent large amounts of hashrate, there’s no reason to assume that they do not control a majority of it, during the attack window. Indeed, most of the 51% attacks on small cryptocurrencies have occurred in GPU-dominated mining environments. In these environments, one needs to think about the security of the system in different terms: Instead of the honest majority assumption, the security assumption underlying liquid mining environments is that a 51%-attacker’s budget is limited and therefore he is unable to spend OpEx-by mining with GPUs or with rented hashpower-for long attack windows.</p><p>The following table compares illiquid and liquid mining environments.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*8FvApr7C_6akuW51wW5ZvA.png\" /></figure><h3>Payment authorization flows</h3><p>In the liquid setup, since the attacker’s budget is affected by the <em>duration</em> of the attack, payments can be confirmed safely after enough <em>time</em> has passed. In the illiquid setup, since the block race between the honest majority and the attacking minority is governed by block creation events, payments can be confirmed safely after enough <em>block creation events</em> occurred. We conclude that block liveness matters in illiquid ASIC-dominated environments. QED.</p><p>Here is a payment authorization flow comparison between Bitcoin and Grin:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/643/0*q0hVhhlU-uClaNA3.png\" /></figure><p>The above compares the payment authorization flows in illiquid, or Bitcoin-like, vs. liquid, or Grin-like, mining environments.⁵ Observe that the attack cost-hence the waiting time for confirmation-does not depend on the block rate, in the liquid setup. In contrast, in an illiquid environment, <em>func(num_of_confs, attacker_rhashrate)</em> does depend on block creation events; so accelerating block times does in fact shorten confirmation times.</p><h3>On the altruistic majority assumption</h3><p>It is useful to recall Satoshi’s original security analysis wherein neither honest miners nor the attacker regard their own incentives: The honest 51% follow the honest mining strategy altruistically, and the malicious 49% are irrational (aka <em>byzantine</em>) and attempt to maximize the damage inflicted or the success probability of the attack (and not the profit!⁶). This is not to say incentives are not underlying the core logic of the system, rather that questions about why a miner would mine honestly or maliciously are discussed outside the security model; they are macro level questions, whereas a client accepting transactions should concern herself with micro level dynamics. It is these macro level arguments that may justify our honest majority assumption. Beware! My thought process here makes “the dumbest assumption of all,” <a href=\"https://twitter.com/NickSzabo4/status/1097020377778122752\">according to Nick Szabo</a> -namely, that Bitcoin’s security strengthens as more CapEx is invested into it. I admit I don’t get it.</p><p>I’m emphasizing Satoshi’s <em>altruistic majority</em> assumption because some people argue that OpEx is essential to security and that without it an attacker could use the same mining resource to mine both good and bad blocks simultaneously (similar to the <a href=\"https://blog.ethereum.org/2014/11/25/proof-stake-learned-love-weak-subjectivity/\">nothing-at-stake</a> criticism of PoS). My counterargument is that the costless simulation phenomenon is noncontinuous and holds only in the absolute zero OpEx case. But either way, this micro level reasoning with respect to mining requires a different-and, in fact, weaker-security model, namely, one which treats malicious (and honest?) miners as rational profit-maximizing agents participating in a game. Understanding these mining dynamics requires thorough analysis of optimal mining strategies, and an attempt at that was started <a href=\"https://arxiv.org/abs/1605.09193\">here</a>; also see <a href=\"https://dl.acm.org/doi/10.1145/2976749.2978341\">this paper</a>. These results show that a rational attacker can in fact maintain long-term profitable attacks, which questions the assumption that attacks are costly and which intrigues rephrasing or rethinking the security model.</p><p>In other words, I disagree with <a href=\"https://twitter.com/BobMcElrath/status/1115945915137908736\">Bob</a>.</p><h3>ASICs are energy-efficient PoW</h3><p>I’m not a fan of liquid mining systems. Yes, they are more democratic; anyone can plug in their GPUs, opt in, plug out, opt out. No barrier-to-entry, no barrier-to-exit. But this is a double-edged sword; “OpEx-heavy” means <em>you burn the security budget by using it</em>. It means the security-by implication, the ability to accelerate confirmation times-can only scale linearly with the amount of resources burnt on the system. To be very very very secure, we need lots and lots and lots of computational resources burnt for us. It works, but it’s inefficient.</p><p>In contrast, “CapEx-heavy” means you are protected by the miners’ investment, which locks them into the system and which is not burnt with every new mined block (outside of a negligible hardware wear).</p><p>It’s like the difference between buying a house and renting it. Your monthly mortgage payment might be similar to the rent, but you never enjoy a month’s rental payment beyond living in the residence for that specific month.</p><p>An ironic implication: Green PoW attempts which use available commodity hardware, such as <a href=\"https://www.chia.net/assets/proof_of_space.pdf\">Chia’s</a> and <a href=\"https://spacemesh.io/post-asic/\">Spacemesh’s proof-of-space</a>, are in fact more wasteful than ASIC-able PoW, because they constantly burn the security budget.</p><p>Pro tip: When dating a Bitcoiner, never tell her you care about energy-efficient PoW. An immediate irreparable turn off.</p><h3>Optimizing for the happy path</h3><p>I would like to finish the blog by making a fool of myself and claiming that the most important threat model is when a no-attacker assumption is applied, formally, <em>attacker_budget</em> = $0 and <em>attacker_rhashrate</em> = 0%.</p><p>In many use cases the payee is not really concerned by the payer carrying out a double spend attack. E.g., in cup-of-coffee-type purchases, or when the merchant knows and trusts the payer-remittance, in-person payments, etc. In such instances, good UX implies a very fast <em>first</em> confirmation time, that is, a short time span between the user broadcasting the payment and the receiver observing it has been mined into the ledger.</p><p>This category includes also cases where the good or service paid for will only be delivered to the buyer at a later date. Such is the case in e-commerce which takes several days to ship, thus providing enough time for the seller before real harm can be done. And such is the case when trading crypto against a centralized exchange, or a crypto-to-fiat gateway, which settles the IOU at a later date, off-chain.</p><p>This <em>time-to-first-confirmation</em> metric is almost always overlooked, as researchers and devs tend to analyze the usability of respective blockchains in a principled methodology, and treat the first confirmation as merely one step towards sufficient (probabilistic) irreversibility of the state. However, while the system is only usable due to its robust worst-case guarantees, real-world usage frequently requires, simply, speedy inclusion in the ledger, which establishes the importance of the <em>time-to-first-confirmation</em> metric.</p><p>Importantly, note that in <a href=\"https://eprint.iacr.org/2018/104.pdf\">PHANTOM</a> and many other DAG-based protocols, valid transactions that entered the DAG and that do not admit double spends will be accepted and admitted to the state regardless of the final ordering; in database language, they are <em>commutative</em> with respect to other transactions co-mined in the same level in the DAG. This implies that an attacker can reverse a payment only if he engaged directly with the victim, i.e., paid the merchant in exchange for another commodity or service and then went on to reverse the transaction. This is in contrast to a single-chain-based protocol where overriding the selected chain automatically overrides all transactions in it.⁷ When we refer to an attacker with <em>attacker_rhashrate</em> = 0 we do <em>not</em> assume, therefore, that 100% of the mining is done by honest nodes, rather that no attacker node engaged with the merchant directly in the to-be-confirmed transaction (or in very recent transactions on which this one depends).</p><p>Finally, and perhaps most importantly, a fast first confirmation is crucial for a good UX for the <em>payer</em>, regardless of the merchant’s waiting and authorization policy. Paying with crypto is an anxiety-inducing process, and an ordinary end-user wants to see the result of her attempts as fast as possible. Bitcoin’s ten minutes is just way too slow, it’s not the way money goes.</p><h3>That’s the way the money goes</h3><p>Impatience is a core trait of the Kaspa community. The main reason we are obsessed with DAGs is we want to see our transactions confirmed at Internet speed, similar to other web-based services. For use cases that require more than one confirmation we know to revisit the app later to check for the final status. Nevertheless, we need this speedy responsiveness out of the crypto app; we want a cryptocurrency to ping and be ponged, and we want it now.</p><p>Impatience will also motivate the smart contract layer design I will propose here [WIP], where I will suggest optimizing for speed rather than for decentralization. Stay tuned, and start getting used to instant confirmations.</p><p>*<a href=\"https://www.youtube.com/watch?v=fOg6JkGa2ic\">Title reference</a></p><p>[1] Or maybe he just kept losing his private keys out of sheer cumbrousness, and he’s now very upset about this whole Bitcoin thing.</p><p>[2] One could challenge this claim if one could provide evidence that there aren’t enough financial instruments and liquidity to profit, in the mentioned order of magnitude, from an hours-long attack on Bitcoin; then one would need to provide a model for confirming transactions based on the existing financial liquidity for such manipulations. Until then, we’re good.</p><p>[3] This term has nothing to do with liquidity mining in DeFi.</p><p>[4] CapEx dominates in the initial days of the ASIC. Of course, as time develops the miner pays more and more OpEx. A mining-informed friend told me that a very rough approximation of the CapEx to OpEx ratio, at the end of the machine’s lifetime, is 1:1. A PoW system which goes more extreme on the CapEx side would use an <a href=\"https://arxiv.org/pdf/1911.05193.pdf\">optical PoW</a> function, which uses cutting-edge optical computing chips. These chips run the central part of the computation on photons, whose interaction does not emit heat, in contrast to electrons running on wire. Also relevant is a paper by Ganesh et. al., suggesting virtual ASICs, a protocol that mimics any point on the CapEx-OpEx spectrum.</p><p>[5] (*) <em>elapsed_time</em> is the time that passed between the transaction being included in the block and now. (**) A more nuanced approach to the <em>attack_cost</em> paradigm would consider additionally the <em>attack_success_probability</em>, for the case of an attacker renting less than 50% of the hashrate. This does not change the qualitative differences between the paradigms, and so to keep things simple I assumed instead that the attacker is &gt;50%, during the attack window, when attacking a liquid mining system. And vice versa: <em>elapsed_time</em> can be used in illiquid mining systems as well, to shorten confirmation times, if the client applies more sophisticated confirmation policies; see <a href=\"https://eprint.iacr.org/2018/040.pdf\">this paper</a>. Still, accelerating block times would accelerate confirmation times in these policies as well.</p><p>[6] For instance, the bounds given by Satoshi on the attacker’s probability of successfully overriding the longest chain are calculated for an attacker that never abandons his one-shot attack, even if many blocks behind. Such an attacker is clearly not concerned with cost and profit.</p><p>[7] Admittedly, transactions removed due to chain reorgs can and in many systems are pushed back to the mempool. However, these transactions are not guaranteed to enter the blockchain in a relevant timeframe, either due to insufficient fees in the post-reorg congestion, or due to users keeping on transacting and innocently double spending previous payments.</p><p><em>Originally published at </em><a href=\"https://blocklivenessmatters.com/blog/patience\"><em>https://blocklivenessmatters.com</em></a><em> on December 28, 2020.</em></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b79ce53726b3\" width=\"1\" />",
    "author": "Yonatan Sompolinsky",
    "published": "2020-12-28",
    "ingested_at": "2025-07-01T11:17:25.455378",
    "source_type": "medium_rss",
    "rss_url": "https://hashdag.medium.com/feed"
  }
]